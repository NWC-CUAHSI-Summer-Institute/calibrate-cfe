{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code renders the parameter config files for CFE-Cver to CFE-Python version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written by Ryoko Araki (San Diego State University & UCSB, raraki8159@sdsu.edu) in 2023 SI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re \n",
    "\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import hydra\n",
    "import yaml\n",
    "import warnings\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "ScannerError",
     "evalue": "while scanning a simple key\n  in \"config.yaml\", line 41, column 1\ncould not find expected ':'\n  in \"config.yaml\", line 42, column 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mScannerError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mconfig.yaml\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m----> 2\u001b[0m     cfg \u001b[39m=\u001b[39m yaml\u001b[39m.\u001b[39;49msafe_load(f)\n\u001b[0;32m      4\u001b[0m \u001b[39m# define GIUH and soil params files\u001b[39;00m\n\u001b[0;32m      5\u001b[0m GIUH_soil_dir \u001b[39m=\u001b[39m cfg[\u001b[39m'\u001b[39m\u001b[39mio_dir\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcfe_c_config_dir\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m$\u001b[39m\u001b[39m{cwd}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m..\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\flipl\\miniconda3\\envs\\CFE-torch\\lib\\site-packages\\yaml\\__init__.py:125\u001b[0m, in \u001b[0;36msafe_load\u001b[1;34m(stream)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msafe_load\u001b[39m(stream):\n\u001b[0;32m    118\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[39m    Parse the first YAML document in a stream\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39m    and produce the corresponding Python object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39m    to be safe for untrusted input.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[39mreturn\u001b[39;00m load(stream, SafeLoader)\n",
      "File \u001b[1;32mc:\\Users\\flipl\\miniconda3\\envs\\CFE-torch\\lib\\site-packages\\yaml\\__init__.py:81\u001b[0m, in \u001b[0;36mload\u001b[1;34m(stream, Loader)\u001b[0m\n\u001b[0;32m     79\u001b[0m loader \u001b[39m=\u001b[39m Loader(stream)\n\u001b[0;32m     80\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[39mreturn\u001b[39;00m loader\u001b[39m.\u001b[39;49mget_single_data()\n\u001b[0;32m     82\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     loader\u001b[39m.\u001b[39mdispose()\n",
      "File \u001b[1;32mc:\\Users\\flipl\\miniconda3\\envs\\CFE-torch\\lib\\site-packages\\yaml\\constructor.py:49\u001b[0m, in \u001b[0;36mBaseConstructor.get_single_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_single_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     48\u001b[0m     \u001b[39m# Ensure that the stream contains a single document and construct it.\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_single_node()\n\u001b[0;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m node \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstruct_document(node)\n",
      "File \u001b[1;32mc:\\Users\\flipl\\miniconda3\\envs\\CFE-torch\\lib\\site-packages\\yaml\\composer.py:36\u001b[0m, in \u001b[0;36mComposer.get_single_node\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m document \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_event(StreamEndEvent):\n\u001b[1;32m---> 36\u001b[0m     document \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompose_document()\n\u001b[0;32m     38\u001b[0m \u001b[39m# Ensure that the stream contains no more documents.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_event(StreamEndEvent):\n",
      "File \u001b[1;32mc:\\Users\\flipl\\miniconda3\\envs\\CFE-torch\\lib\\site-packages\\yaml\\composer.py:55\u001b[0m, in \u001b[0;36mComposer.compose_document\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_event()\n\u001b[0;32m     54\u001b[0m \u001b[39m# Compose the root node.\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompose_node(\u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m     57\u001b[0m \u001b[39m# Drop the DOCUMENT-END event.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_event()\n",
      "File \u001b[1;32mc:\\Users\\flipl\\miniconda3\\envs\\CFE-torch\\lib\\site-packages\\yaml\\composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     82\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[0;32m     83\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[1;32m---> 84\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompose_mapping_node(anchor)\n\u001b[0;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mascend_resolver()\n\u001b[0;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[1;32mc:\\Users\\flipl\\miniconda3\\envs\\CFE-torch\\lib\\site-packages\\yaml\\composer.py:133\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    129\u001b[0m item_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompose_node(node, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    130\u001b[0m \u001b[39m#if item_key in node.value:\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m item_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompose_node(node, item_key)\n\u001b[0;32m    134\u001b[0m \u001b[39m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[0;32m    135\u001b[0m node\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mappend((item_key, item_value))\n",
      "File \u001b[1;32mc:\\Users\\flipl\\miniconda3\\envs\\CFE-torch\\lib\\site-packages\\yaml\\composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[1;34m(self, parent, index)\u001b[0m\n\u001b[0;32m     82\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompose_sequence_node(anchor)\n\u001b[0;32m     83\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[1;32m---> 84\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompose_mapping_node(anchor)\n\u001b[0;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mascend_resolver()\n\u001b[0;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m node\n",
      "File \u001b[1;32mc:\\Users\\flipl\\miniconda3\\envs\\CFE-torch\\lib\\site-packages\\yaml\\composer.py:127\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[1;34m(self, anchor)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39mif\u001b[39;00m anchor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manchors[anchor] \u001b[39m=\u001b[39m node\n\u001b[1;32m--> 127\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_event(MappingEndEvent):\n\u001b[0;32m    128\u001b[0m     \u001b[39m#key_event = self.peek_event()\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     item_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompose_node(node, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    130\u001b[0m     \u001b[39m#if item_key in node.value:\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     \u001b[39m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[39m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\flipl\\miniconda3\\envs\\CFE-torch\\lib\\site-packages\\yaml\\parser.py:98\u001b[0m, in \u001b[0;36mParser.check_event\u001b[1;34m(self, *choices)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_event \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate:\n\u001b[1;32m---> 98\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate()\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_event \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m choices:\n",
      "File \u001b[1;32mc:\\Users\\flipl\\miniconda3\\envs\\CFE-torch\\lib\\site-packages\\yaml\\parser.py:428\u001b[0m, in \u001b[0;36mParser.parse_block_mapping_key\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_block_mapping_key\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 428\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_token(KeyToken):\n\u001b[0;32m    429\u001b[0m         token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_token()\n\u001b[0;32m    430\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_token(KeyToken, ValueToken, BlockEndToken):\n",
      "File \u001b[1;32mc:\\Users\\flipl\\miniconda3\\envs\\CFE-torch\\lib\\site-packages\\yaml\\scanner.py:115\u001b[0m, in \u001b[0;36mScanner.check_token\u001b[1;34m(self, *choices)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_token\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mchoices):\n\u001b[0;32m    114\u001b[0m     \u001b[39m# Check if the next token is one of the given types.\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mneed_more_tokens():\n\u001b[0;32m    116\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfetch_more_tokens()\n\u001b[0;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokens:\n",
      "File \u001b[1;32mc:\\Users\\flipl\\miniconda3\\envs\\CFE-torch\\lib\\site-packages\\yaml\\scanner.py:152\u001b[0m, in \u001b[0;36mScanner.need_more_tokens\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[39m# The current token may be a potential simple key, so we\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[39m# need to look further.\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstale_possible_simple_keys()\n\u001b[0;32m    153\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_possible_simple_key() \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokens_taken:\n\u001b[0;32m    154\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\flipl\\miniconda3\\envs\\CFE-torch\\lib\\site-packages\\yaml\\scanner.py:291\u001b[0m, in \u001b[0;36mScanner.stale_possible_simple_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mline \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mline  \\\n\u001b[0;32m    289\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m-\u001b[39mkey\u001b[39m.\u001b[39mindex \u001b[39m>\u001b[39m \u001b[39m1024\u001b[39m:\n\u001b[0;32m    290\u001b[0m     \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mrequired:\n\u001b[1;32m--> 291\u001b[0m         \u001b[39mraise\u001b[39;00m ScannerError(\u001b[39m\"\u001b[39m\u001b[39mwhile scanning a simple key\u001b[39m\u001b[39m\"\u001b[39m, key\u001b[39m.\u001b[39mmark,\n\u001b[0;32m    292\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mcould not find expected \u001b[39m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_mark())\n\u001b[0;32m    293\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpossible_simple_keys[level]\n",
      "\u001b[1;31mScannerError\u001b[0m: while scanning a simple key\n  in \"config.yaml\", line 41, column 1\ncould not find expected ':'\n  in \"config.yaml\", line 42, column 1"
     ]
    }
   ],
   "source": [
    "with open('config.yaml', 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "    \n",
    "# define GIUH and soil params files\n",
    "GIUH_soil_dir = cfg['io_dir']['cfe_c_config_dir'].replace(\"${cwd}\", \"..\")\n",
    "\n",
    "# define basin list dir\n",
    "basin_dir = cfg['io_dir']['gauch_2020_dir'].replace(\"${cwd}\", \"..\")\n",
    "basin_filename = cfg['model_settings']['basin_file'].replace(\"${cwd}\", \"..\") # It was 516 basin in 2022 code \n",
    "\n",
    "# define camel dataset dir\n",
    "camels_attr_dir = cfg['io_dir']['ucar_dir'].replace(\"${cwd}\", \"..\")\n",
    "\n",
    "# define atmospheric forcing file dir\n",
    "forcing_path = cfg['io_dir']['nldas_forcing_dir'].replace(\"${cwd}\", \"..\")\n",
    "\n",
    "# define dir for exported json\n",
    "config_dir = cfg['io_dir']['config_dir'].replace(\"${cwd}\", \"..\")\n",
    "\n",
    "soil_scheme = cfg['CFE_config']['soil_scheme']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(basin_filename, \"r\") as f:\n",
    "    basin_list = pd.read_csv(f, header=None)\n",
    "\n",
    "with open(basin_filename, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    # Remove leading/trailing whitespaces and newline characters\n",
    "    lines = [line.strip() for line in lines]\n",
    "basin_list_str = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2252.70\n",
       "1     573.60\n",
       "2    3676.17\n",
       "3     769.05\n",
       "4     909.10\n",
       "Name: area_gages2, dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basin_attributes = pd.read_csv(os.path.join(camels_attr_dir, 'camels_attributes_concat.csv'))\n",
    "basin_attributes['gauge_id'] = basin_attributes['gauge_id'].astype(str).str.zfill(8)\n",
    "basin_attributes['area_gages2'].head()\n",
    "\n",
    "# See https://hess.copernicus.org/preprints/hess-2017-169/hess-2017-169.pdf for the definition\n",
    "# attribute: are_gages2\n",
    "# Description: catchment area (GAGESII estimate)\n",
    "# Unit: [km2]\n",
    "# Data source: N15-USGSdata\n",
    "# Reference: Falcone (2011)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the number of parameter files in the C version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of config files that 2022 team received from Luciana: 519\n",
      "Number of the gauges matching with our basin of interest: 516/516\n"
     ]
    }
   ],
   "source": [
    "file_count = sum(1 for _ in os.scandir(GIUH_soil_dir) if _.is_file())\n",
    "\n",
    "pattern = r'(\\d+)\\_bmi_config_cfe_pass.txt'\n",
    "basin_ids_in_c_config = []\n",
    "for filename in os.listdir(GIUH_soil_dir):\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        basin_id = match.group(1)\n",
    "        basin_ids_in_c_config.append(basin_id)\n",
    "        \n",
    "print(f\"Number of config files that 2022 team received from Luciana: {file_count}\")\n",
    "common_gauges = set(basin_ids_in_c_config) & set(basin_list_str)\n",
    "print(f\"Number of the gauges matching with our basin of interest: {len(common_gauges)}/516\")\n",
    "\n",
    "if len(common_gauges) != 516:\n",
    "    warnings.warn(\"Config missing in either of the folders\")\n",
    "else:\n",
    "    None\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and render the config files (C -> BMIpy readable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_config(GIUH_soil_dir, basin_id):\n",
    "    # get giuh and soil param file\n",
    "    giuh_soil_file = os.path.join(GIUH_soil_dir, f'{basin_id}_bmi_config_cfe_pass.txt')\n",
    "    with open(giuh_soil_file, \"r\") as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "\n",
    "def render_config(basin_id, text, default_values):\n",
    "    \n",
    "    # Initialize\n",
    "    parameters = dict()\n",
    "    parameters['soil_params'] = dict()\n",
    "    lines = text.strip().split(\"\\n\")\n",
    "    \n",
    "    parameters['forcing_file'] = os.path.join(forcing_path, f'{basin_id}_hourly_nldas.csv')\n",
    "    parameters['catchment_area_km2'] = basin_attributes['area_gages2'][basin_attributes.gauge_id == basin_id].values[0]\n",
    "\n",
    "    # Loop through the lines \n",
    "    for line in lines:\n",
    "        key, value = line.split(\"=\")\n",
    "        key_parts = key.split(\".\")\n",
    "        param_name = key_parts[-1].strip()\n",
    "        \n",
    "        if \"[\" in value:\n",
    "            value = value.split(\"[\")[0].strip()\n",
    "        \n",
    "        if param_name in default_values and value != \"NaN\":\n",
    "            \n",
    "            if \",\" in value:\n",
    "                value = [float(v) for v in value.split(\",\")]\n",
    "            else:\n",
    "                try:\n",
    "                    value = float(value)\n",
    "                except ValueError:\n",
    "                    value = default_values[param_name]\n",
    "                    Warning('Detected NaN in original config file. Replaced with default values.')\n",
    "            \n",
    "            if param_name == \"b\":\n",
    "                param_name = \"bb\"\n",
    "\n",
    "            if param_name in [\"depth\", \"satdk\", \"satpsi\", \"slop\", \"smcmax\", \"wltsmc\", \"bb\"]:\n",
    "                parameters[\"soil_params\"][param_name] = value\n",
    "            else:        \n",
    "                parameters[param_name] = value\n",
    "\n",
    "    # Some default CFE-py parameters not generated through Hydrofabric\n",
    "    parameters['stand_alone'] = 1 \n",
    "    parameters['unit_test'] = 0\n",
    "    parameters['compare_results_file'] = \"\"\n",
    "    parameters['partition_scheme'] = \"Schaake\"\n",
    "    parameters['soil_scheme'] = soil_scheme\n",
    "    parameters['soil_params'][\"D\"] = 2.0\n",
    "    parameters[\"soil_params\"][\"mult\"] = 1000.0\n",
    "\n",
    "    return parameters\n",
    "\n",
    "def save_rendered_config(basin_id, config_dir, parameters):\n",
    "    # save and export json files\n",
    "    json_filename = f'cat_{basin_id}_bmi_config_cfe___ryokotesting.json'\n",
    "    json_file = os.path.join(config_dir, json_filename)\n",
    "    with open(json_file, 'w') as file:\n",
    "        json.dump(parameters, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.73it/s]\n"
     ]
    }
   ],
   "source": [
    "default_values = {\n",
    "    \"depth\": 2.0,\n",
    "    \"b\": 5.651162790697675,\n",
    "    \"satdk\": 1.28959488372093e-05,\n",
    "    \"satpsi\": 0.0662031693860465,\n",
    "    \"slop\": 0.013278359525581396,\n",
    "    \"smcmax\": 0.46032193756744183,\n",
    "    \"wltsmc\": 0.023237335009302328,\n",
    "    \"expon\": 1.0,\n",
    "    \"expon_secondary\": 1.0,\n",
    "    \"refkdt\": 1.0, \n",
    "    \"max_gw_storage\": 0.011877697944999994,\n",
    "    \"Cgw\": 1.8e-05,\n",
    "    \"gw_storage\": 0.05,\n",
    "    \"alpha_fc\":0.33,\n",
    "    \"K_nash\": 0.03,\n",
    "    \"K_lf\": 0.01,\n",
    "    \"nash_storage\": \"0.0,0.0\",\n",
    "    \"giuh_ordinates\": \"0.1, 0.2, 0.4, 0.2, 0.1\"\n",
    "}\n",
    "\n",
    "basin_id = basin_list_str[0]\n",
    "# for basin_id in tqdm(basin_list_str):\n",
    "for basin_id in tqdm([basin_list_str[0]]):\n",
    "    text = load_config(GIUH_soil_dir=GIUH_soil_dir, basin_id=basin_id)\n",
    "    parameters = render_config(basin_id=basin_id, text=text, default_values=default_values)\n",
    "    save_rendered_config(basin_id=basin_id, config_dir=config_dir, parameters=parameters)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if all the configs are generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of config files that 2022 team received from Luciana: 241\n",
      "Number of the gauges matching with our basin of interest: 237/516\n",
      "missing gauges are: {'14222500', '07346045', '08050800', '08196000', '08086290', '09312600', '06903400', '06289000', '05525500', '09510200', '13011500', '12488500', '09497980', '07180500', '06409000', '12013500', '14301000', '14303200', '07167500', '08086212', '06919500', '07301410', '12010000', '12189500', '14187000', '09494000', '11475560', '12054000', '05454000', '05444000', '07145700', '05413500', '07362587', '12411000', '11176400', '05399500', '09066300', '10234500', '08194200', '11284400', '08378500', '09512280', '12178100', '12035000', '06311000', '06885500', '11266500', '05593575', '05393500', '07261000', '05489000', '08158810', '12451000', '06406000', '06888500', '05592575', '09508300', '06447500', '12381400', '05466500', '05508805', '13235000', '14309500', '06892000', '14308990', '06601000', '14306340', '14362250', '08200000', '06889200', '05057200', '05595730', '09066200', '05408000', '12147500', '13313000', '08324000', '06221400', '06470800', '12025700', '04296000', '06917000', '13161500', '05291000', '07362100', '05495000', '08190000', '09378170', '12082500', '13331500', '13240000', '14138870', '09306242', '14141500', '05488200', '11148900', '11468500', '08150800', '05592050', '12041200', '07197000', '08195000', '08176900', '12377150', '12115000', '06614800', '05556500', '06632400', '08103900', '07263295', '08271000', '08066200', '11480390', '06906800', '09513780', '05487980', '14020000', '11451100', '11528700', '06910800', '06350000', '12143600', '07340300', '08178880', '06280300', '14185900', '11482500', '11476600', '06879650', '14325000', '06278300', '07060710', '07184000', '06431500', '07195800', '12048000', '05414000', '14306500', '12447390', '14096850', '05120500', '14138900', '08164300', '06878000', '12092000', '13018300', '07359610', '05458000', '07142300', '06746095', '14182500', '09505350', '09505800', '12167000', '14316700', '06440200', '06352000', '08189500', '13023000', '07375000', '08190500', '07335700', '09065500', '09035900', '10259000', '07315700', '14185000', '05584500', '05362000', '11478500', '06876700', '07291000', '06911900', '09066000', '08066300', '06921200', '06344600', '08023080', '12375900', '08013000', '11381500', '12390700', '11522500', '14305500', '09430600', '12144000', '10336645', '11151300', '06332515', '12056500', '07083000', '08101000', '07299670', '06404000', '04221000', '11141280', '06479215', '12117000', '10343500', '06803530', '08175000', '10244950', '07196900', '06847900', '12040500', '07208500', '08070200', '08380500', '06814000', '04224775', '14138800', '09386900', '08202700', '05591550', '11473900', '11124500', '09404450', '06477500', '12145500', '12020000', '07066000', '12073500', '08082700', '12175500', '05507600', '06224000', '04256000', '08267500', '14154500', '14137000', '08164600', '09492400', '14216500', '06853800', '11264500', '06339100', '07057500', '14139800', '06918460', '09047700', '08269000', '05593900', '09484600', '08104900', '06622700', '09447800', '11143000', '08109700', '12114500', '05501000', '11481200', '13011900', '08165300', '06623800', '09352900', '10336660', '14166500', '14400000', '14236200', '06921070', '08014500', '08377900', '07315200', '09107000', '08171300', '11532500', '08158700', '11523200', '06889500', '05503800', '09081600', '14158790', '08070000', '09210500', '12186000', '05495500', '08198500', '09223000', '06803510'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\Temp\\ipykernel_8628\\201170502.py:17: UserWarning: Config missing in either of the directories\n",
      "  warnings.warn(\"Config missing in either of the directories\")\n"
     ]
    }
   ],
   "source": [
    "file_count = sum(1 for _ in os.scandir(config_dir) if _.is_file())\n",
    "\n",
    "pattern = r'cat_(\\d+)\\_bmi_config_cfe.json'\n",
    "basin_ids_in_py_config = []\n",
    "for filename in os.listdir(config_dir):\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        basin_id = match.group(1)\n",
    "        basin_ids_in_py_config.append(basin_id)\n",
    "        \n",
    "print(f\"Number of config files that 2022 team received from Luciana: {file_count}\")\n",
    "common_gauges = set(basin_ids_in_py_config) & set(basin_list_str)\n",
    "missing_gauges = set(basin_list_str) - set(basin_ids_in_py_config)\n",
    "print(f\"Number of the gauges matching with our basin of interest: {len(common_gauges)}/516\")\n",
    "\n",
    "if len(common_gauges) != 516:\n",
    "    warnings.warn(\"Config missing in either of the directories\")\n",
    "    print(f\"missing gauges are: {missing_gauges}\")\n",
    "else:\n",
    "    None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CFE-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
