{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define basin list dir\n",
    "basin_dir = r'..\\data\\camels\\gauch_etal_2020'\n",
    "basin_filename = 'basin_list_516.txt'\n",
    "output_dir = basin_dir\n",
    "\n",
    "# define observation file dir\n",
    "#obs_dir = os.path.join(working_dir,'usgs-streamflow')\n",
    "obs_dir = r'..\\data\\camels\\gauch_etal_2020\\usgs_streamflow'\n",
    "\n",
    "# define atmospheric forcing file dir\n",
    "forcing_path = r'..\\data\\camels\\gauch_etal_2020\\nldas_hourly'\n",
    "\n",
    "# define the spinup-calib-val period\n",
    "time_split_file = r'..\\data\\model_common_configs\\cal-val-test-period.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_basin_list(basin_file):\n",
    "    with open(basin_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    lines = [line.strip() for line in lines]\n",
    "    return lines\n",
    "\n",
    "def load_csv(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def calc_nan_percentages_forcing(forcing_data, fields):\n",
    "    return [len(np.where(np.isnan(forcing_data[field]))[0]) / len(forcing_data[field]) for field in fields]\n",
    "\n",
    "def calc_nan_percentages_obs(obs_data):\n",
    "    return len(np.where(np.isnan(obs_data['QObs(mm/h)'].values))[0]) / len(obs_data['QObs(mm/h)'])\n",
    "\n",
    "def calc_indices(data, datetime):\n",
    "    start_idx = np.where(data['date'] == datetime[\"start_datetime\"])\n",
    "    end_idx = np.where(data['date'] == datetime[\"end_datetime\"])\n",
    "    return start_idx, end_idx\n",
    "\n",
    "def initialize_nan_check():\n",
    "    keys = [\n",
    "            'basin id', \n",
    "            'spinup-for-calibration - pet', 'spinup-for-calibration - precip', \n",
    "            'spinup-for-testing - pet', 'spinup-for-testing - precip', \n",
    "            'calibration - pet', 'calibration - precip', 'calibration - usgs', \n",
    "            'testing - pet', 'testing - precip', 'testing - usgs'\n",
    "            ]\n",
    "    return {key: [] for key in keys}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/516 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 37/516 [00:45<10:11,  1.28s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_data(data_dir, obs_dir, forcing_path, time_split_file, output_dir):\n",
    "    \n",
    "    nan_check = initialize_nan_check()\n",
    "\n",
    "    basin_list = load_basin_list(os.path.join(data_dir, 'basin_list_516.txt'))\n",
    "    time_split = json.load(open(time_split_file, 'r'))\n",
    "\n",
    "    for basin in tqdm(basin_list):\n",
    "        obs_data = load_csv(os.path.join(obs_dir, f'{basin}-usgs-hourly.csv'))\n",
    "        forcing_data = load_csv(os.path.join(forcing_path, f'{basin}_hourly_nldas.csv'))\n",
    "\n",
    "        for phase, fields in time_split.items():\n",
    "            \n",
    "            # Forcing \n",
    "            start_idx_forcing, end_idx_forcing = calc_indices(forcing_data, fields)\n",
    "            if start_idx_forcing[0].size == 0 or end_idx_forcing[0].size == 0: \n",
    "                print(f\"none or missing forcing data for {phase} period\")\n",
    "                nan_perc = [1, 1]\n",
    "            else:\n",
    "                sliced_forcing_data = forcing_data.iloc[start_idx_forcing[0][0]:end_idx_forcing[0][0]+1,:]\n",
    "                nan_perc = calc_nan_percentages_forcing(sliced_forcing_data, ['potential_evaporation', 'total_precipitation'])\n",
    "                \n",
    "            # Observation\n",
    "            start_idx_obs, end_idx_obs = calc_indices(obs_data, fields)\n",
    "            if start_idx_obs[0].size == 0 or end_idx_obs[0].size == 0: \n",
    "                print(f\"none or missing observation data for {phase} period\")\n",
    "                nan_perc_obs = 1\n",
    "            else:\n",
    "                sliced_obs_data = obs_data.iloc[start_idx_obs[0][0]:end_idx_obs[0][0]+1,:]\n",
    "                nan_perc_obs = calc_nan_percentages_obs(sliced_obs_data)\n",
    "                \n",
    "            nan_check[f'{phase} - pet'].append(nan_perc[0])\n",
    "            nan_check[f'{phase} - precip'].append(nan_perc[1])\n",
    "            if \"spinup\" not in phase:\n",
    "                nan_check[f'{phase} - usgs'].append(nan_perc_obs)\n",
    "\n",
    "    df = pd.DataFrame(nan_check)\n",
    "    df.to_csv(os.path.join(output_dir, \"check_for_nan_in_data_hourly.csv\"))\n",
    "\n",
    "data_dir = os.path.join('..', 'data', 'camels', 'gauch_etal_2020')\n",
    "obs_dir = os.path.join(data_dir, 'usgs_streamflow')\n",
    "forcing_path = os.path.join(data_dir, 'nldas_hourly')\n",
    "time_split_file = os.path.join('..', 'data', 'model_common_configs', 'cal-val-test-period.json')\n",
    "output_dir = data_dir\n",
    "\n",
    "process_data(data_dir, obs_dir, forcing_path, time_split_file, output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CFE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
