{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline (download various dataset/scripts)\n",
    "\n",
    "This code download the following items\n",
    "- CFE model scripts from github repo\n",
    "- Hydroshare resources\n",
    "    - Hydofabric outputs\n",
    "    - CFE (C-version) parameter config files for CAMELS catchments from Hydroshare\n",
    "- CAMELS-US dataset from Zenodo by Gauch et al., (2020)\n",
    "- CAMELS-US attributes from UCAR server\n",
    "\n",
    "To be edited  \n",
    "Written by Ryoko Araki (San Diego State University & UCSB, raraki8159@sdsu.edu) in 2023 SI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wget\n",
    "from tqdm import tqdm\n",
    "import tarfile\n",
    "import yaml\n",
    "import requests\n",
    "from hsclient import HydroShare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://github.com/hydroshare/hsclient/ to check Hydroshare Python Client documentations\n",
    "hs = HydroShare()\n",
    "hs.sign_in()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_mode = 'Python' #['Python','CLI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the config file\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Access the config variables\n",
    "data_dir = config['io_dir']['data_dir'].replace(\"${cwd}\", \"..\")\n",
    "camels_dir = config['io_dir']['camels_dir'].replace(\"${cwd}\", \"..\")\n",
    "camels_data_dir = config['io_dir']['gauch_2020_dir'].replace(\"${cwd}\", \"..\")\n",
    "camels_attr_dir = config['io_dir']['ucar_dir'].replace(\"${cwd}\", \"..\")\n",
    "usgs_dir = config['io_dir']['usgs_streamflow_dir'].replace(\"${cwd}\", \"..\")\n",
    "nldas_dir = config['io_dir']['nldas_forcing_dir'].replace(\"${cwd}\", \"..\")\n",
    "basin_filename = config['model_settings']['basin_file'].replace(\"${cwd}\", \"..\")\n",
    "config_dir = config['io_dir']['config_dir'].replace(\"${cwd}\", \"..\")\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "if not os.path.exists(camels_dir):\n",
    "    os.mkdir(camels_dir)\n",
    "if not os.path.exists(camels_data_dir):\n",
    "    os.mkdir(camels_data_dir)\n",
    "if not os.path.exists(camels_attr_dir):\n",
    "    os.mkdir(camels_attr_dir) \n",
    "if not os.path.exists(config_dir):\n",
    "    os.mkdir(config_dir) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone Git repo  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/NWC-CUAHSI-Summer-Institute/cfe_py ../cfe_py\n",
    "\n",
    "# if it already exist, git pull in the directory to get the updated version of cfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download initial parameter configuration\n",
    "https://www.hydroshare.org/resource/f7d6db8f8677402d808531924bbcf60c/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just retrieved the resource with ID: f7d6db8f8677402d808531924bbcf60c\n"
     ]
    }
   ],
   "source": [
    "# Get the HydroShare identifier for the new resource\n",
    "resIdentifier = \"f7d6db8f8677402d808531924bbcf60c\"\n",
    "# Get an existing resource using its identifier\n",
    "existing_resource = hs.resource(resIdentifier)\n",
    "print('Just retrieved the resource with ID: ' + resIdentifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\calibrate_cfe\\\\configs\\\\soil_ode\\\\CFE_Config_Cver_from_Luciana.zip'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_param_file = existing_resource.file(path=\"config/CFE_Config_Cver_from_Luciana.zip\")\n",
    "existing_resource.file_download(init_param_file, save_path=config_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "init_param_path = os.path.join(config_dir, \"CFE_Config_Cver_from_Luciana.zip\")\n",
    "with zipfile.ZipFile(init_param_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(config_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download CAMELS observation & forcing (Gauch et al., 2020)\n",
    "This notebook downloads CAMELS data, loads them into memory, cleans that data then saves a cleaned data product, which may be used later on for some analysis.\n",
    "\n",
    "Written by Ryoko Araki (San Diego State University & UCSB, raraki8159@sdsu.edu) in 2023 SI \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download files from on-line host.\n",
    "Homepage: https://zenodo.org/record/4072701/\n",
    "\n",
    "Citation: Gauch, Martin, Kratzert, Frederik, Klotz, Daniel, Nearing, Grey, Lin, Jimmy, & Hochreiter, Sepp. (2020). Data for \"Rainfall-Runoff Prediction at Multiple Timescales with a Single Long Short-Term Memory Network\" [Data set]. Zenodo. https://doi.org/10.5281/zenodo.4072701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_head = r'https://zenodo.org/record/4072701/files/'\n",
    "url_end = '?download=1'\n",
    "camels_files = [\n",
    "    'README.md',\n",
    "    'usgs_streamflow_csv.tar.gz',\n",
    "    'nldas_hourly_csv.tar.gz',\n",
    "    'usgs-streamflow-nldas_hourly.nc',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wget through Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if download_mode == 'Python':\n",
    "    for camels_file in tqdm(camels_files):\n",
    "        url = url_head + camels_file + url_end\n",
    "        print(f\"Processing: {url}\")\n",
    "        wget.download(url, out=camels_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the Linux environment, you can also run a bash file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "DATA_DIR=\"../data/camels/\"\n",
    "if [ -d \"$DATA_DIR\" ]; then rm -Rf $DATA_DIR; fi\n",
    "mkdir $DATA_DIR\n",
    "filenames=(nldas_hourly_csv.tar.gz README.md usgs-streamflow-nldas_hourly.nc usgs_streamflow_csv.tar.gz)\n",
    "for filename in ${filenames[@]}\n",
    "do\n",
    "    wget -O \"${DATA_DIR}${filename}\" \"https://zenodo.org/record/4072701/files/${filename}?download=1\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2]:\n",
    "    # 1 for the usgs-streamflow\n",
    "    # 2 for the nldas-forcing\n",
    "    filename = os.path.join(camels_data_dir, camels_files[i])\n",
    "    if os.path.exists(filename):\n",
    "        with tarfile.open(filename, 'r:gz') as tar:\n",
    "            # Extract all files in the tar.gz file\n",
    "            tar.extractall(path=camels_data_dir)\n",
    "    else:\n",
    "        print('The file hasn\\'t been downloaded yet')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the list of gauge ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = []\n",
    "file_names = os.listdir(os.path.join(camels_data_dir, 'usgs_streamflow'))  # Get all file names in the folder\n",
    "\n",
    "# Loop through files in the folder\n",
    "for file_name in file_names:\n",
    "    # Extract the first 8 digits of the file name\n",
    "    file_id = file_name[:8]\n",
    "    id_list.append(file_id)\n",
    "sorted_id_list = sorted(id_list)\n",
    "\n",
    "# Save the list as a text file\n",
    "with open(basin_filename, 'w') as file:\n",
    "    for item in sorted_id_list:\n",
    "        file.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the number of files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'# USGS streamflow files: {len(file_names)}') # Should be 516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_list = []\n",
    "file_names = os.listdir(os.path.join(camels_data_dir, 'nldas_hourly'))  # Get all file names in the folder\n",
    "\n",
    "# Loop through files in the folder\n",
    "for file_name in file_names:\n",
    "    # Extract the first 8 digits of the file name\n",
    "    file_id = file_name[:8]\n",
    "    id_list.append(file_id)\n",
    "sorted_id_list = sorted(id_list)\n",
    "\n",
    "print(f'# NLDAS forcing files: {len(sorted_id_list)}') # Should be 671"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Download CAMELs attributes (UCAR)\n",
    "### Download the data\n",
    "\n",
    "Home page: https://gdex.ucar.edu/dataset/camels.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=[\n",
    "    \"camels_clim.txt\",\n",
    "    \"camels_geol.txt\",\n",
    "    \"camels_hydro.txt\",\n",
    "    \"camels_name.txt\",\n",
    "    \"camels_soil.txt\",\n",
    "    \"camels_topo.txt\",\n",
    "    \"camels_vege.txt\"\n",
    "    ]\n",
    "\n",
    "md5_checksums = [\n",
    "    '67f22592f3fb72c57df81358ce68458b',\n",
    "    'f5ce5de53eb1ea2532cda7e3b4813993',\n",
    "    '55ebdeb36c42ee7acdb998229c3edb3a',\n",
    "    'c96491b32c4df55a31bead7ceca7d64b',\n",
    "    '8edb46a363a20b466a4b7105ba633767',\n",
    "    '0f6267838c40b1507b64582433bc0b8e',\n",
    "    'f40e843defc1e654a800be9fe5fd5090'\n",
    "    ]\n",
    "url_head = r'https://gdex.ucar.edu/api/v1/dataset/camels/file/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wget through Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_clim.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "1it [00:00,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully.\n",
      "Processing: https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_geol.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "2it [00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully.\n",
      "Processing: https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_hydro.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "3it [00:01,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully.\n",
      "Processing: https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_name.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "4it [00:01,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully.\n",
      "Processing: https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_soil.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "5it [00:02,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully.\n",
      "Processing: https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_topo.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "6it [00:02,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully.\n",
      "Processing: https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_vege.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:03,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "if download_mode == 'Python':\n",
    "\n",
    "    # Download the data\n",
    "    for camels_file, md5_checksum in tqdm(zip(filenames, md5_checksums)):\n",
    "        url = url_head + camels_file\n",
    "        print(f\"Processing: {url}\")\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            with open(os.path.join(camels_attr_dir, camels_file), 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(\"File downloaded successfully.\")\n",
    "        else:\n",
    "            print(\"Failed to download the file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the Linux environment, you can also run a bash file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "DATA_DIR=\"../data/camels/ucar/\"\n",
    "if [ -d \"$DATA_DIR\" ]; then rm -Rf $DATA_DIR; fi\n",
    "mkdir $DATA_DIR\n",
    "filenames=(camels_clim.txt, camels_geol.txt camels_hydro.txt camels_name.txt camels_soil.txt camels_topo.txt camels_vege.txt)\n",
    "for filename in ${filenames[@]}\n",
    "do \n",
    "    wget -O \"${DATA_DIR}${filename}\" \"https://zenodo.org/record/4072701/files/${filename}?download=1\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_mean</th>\n",
       "      <th>pet_mean</th>\n",
       "      <th>p_seasonality</th>\n",
       "      <th>frac_snow</th>\n",
       "      <th>aridity</th>\n",
       "      <th>high_prec_freq</th>\n",
       "      <th>high_prec_dur</th>\n",
       "      <th>high_prec_timing</th>\n",
       "      <th>low_prec_freq</th>\n",
       "      <th>low_prec_dur</th>\n",
       "      <th>...</th>\n",
       "      <th>area_geospa_fabric</th>\n",
       "      <th>frac_forest</th>\n",
       "      <th>lai_max</th>\n",
       "      <th>lai_diff</th>\n",
       "      <th>gvf_max</th>\n",
       "      <th>gvf_diff</th>\n",
       "      <th>dom_land_cover_frac</th>\n",
       "      <th>dom_land_cover</th>\n",
       "      <th>root_depth_50</th>\n",
       "      <th>root_depth_99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gauge_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1013500</th>\n",
       "      <td>3.126679</td>\n",
       "      <td>1.971555</td>\n",
       "      <td>0.187940</td>\n",
       "      <td>0.313440</td>\n",
       "      <td>0.630559</td>\n",
       "      <td>12.95</td>\n",
       "      <td>1.348958</td>\n",
       "      <td>son</td>\n",
       "      <td>202.20</td>\n",
       "      <td>3.427119</td>\n",
       "      <td>...</td>\n",
       "      <td>2303.95</td>\n",
       "      <td>0.9063</td>\n",
       "      <td>4.167304</td>\n",
       "      <td>3.340732</td>\n",
       "      <td>0.804567</td>\n",
       "      <td>0.371648</td>\n",
       "      <td>0.883452</td>\n",
       "      <td>Mixed Forests</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022500</th>\n",
       "      <td>3.608126</td>\n",
       "      <td>2.119256</td>\n",
       "      <td>-0.114530</td>\n",
       "      <td>0.245259</td>\n",
       "      <td>0.587356</td>\n",
       "      <td>20.55</td>\n",
       "      <td>1.205279</td>\n",
       "      <td>son</td>\n",
       "      <td>233.65</td>\n",
       "      <td>3.662226</td>\n",
       "      <td>...</td>\n",
       "      <td>620.38</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>4.871392</td>\n",
       "      <td>3.746692</td>\n",
       "      <td>0.863936</td>\n",
       "      <td>0.337712</td>\n",
       "      <td>0.820493</td>\n",
       "      <td>Mixed Forests</td>\n",
       "      <td>0.237435</td>\n",
       "      <td>2.238444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030500</th>\n",
       "      <td>3.274405</td>\n",
       "      <td>2.043594</td>\n",
       "      <td>0.047358</td>\n",
       "      <td>0.277018</td>\n",
       "      <td>0.624111</td>\n",
       "      <td>17.15</td>\n",
       "      <td>1.207746</td>\n",
       "      <td>son</td>\n",
       "      <td>215.60</td>\n",
       "      <td>3.514262</td>\n",
       "      <td>...</td>\n",
       "      <td>3676.09</td>\n",
       "      <td>0.8782</td>\n",
       "      <td>4.685200</td>\n",
       "      <td>3.665543</td>\n",
       "      <td>0.858502</td>\n",
       "      <td>0.351393</td>\n",
       "      <td>0.975258</td>\n",
       "      <td>Mixed Forests</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031500</th>\n",
       "      <td>3.522957</td>\n",
       "      <td>2.071324</td>\n",
       "      <td>0.104091</td>\n",
       "      <td>0.291836</td>\n",
       "      <td>0.587950</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1.148936</td>\n",
       "      <td>son</td>\n",
       "      <td>227.35</td>\n",
       "      <td>3.473644</td>\n",
       "      <td>...</td>\n",
       "      <td>766.53</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>4.903259</td>\n",
       "      <td>3.990843</td>\n",
       "      <td>0.870668</td>\n",
       "      <td>0.398619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Mixed Forests</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047000</th>\n",
       "      <td>3.323146</td>\n",
       "      <td>2.090024</td>\n",
       "      <td>0.147776</td>\n",
       "      <td>0.280118</td>\n",
       "      <td>0.628929</td>\n",
       "      <td>20.10</td>\n",
       "      <td>1.165217</td>\n",
       "      <td>son</td>\n",
       "      <td>235.90</td>\n",
       "      <td>3.691706</td>\n",
       "      <td>...</td>\n",
       "      <td>904.94</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>5.086811</td>\n",
       "      <td>4.300978</td>\n",
       "      <td>0.891383</td>\n",
       "      <td>0.445473</td>\n",
       "      <td>0.850450</td>\n",
       "      <td>Mixed Forests</td>\n",
       "      <td>0.241027</td>\n",
       "      <td>2.340180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            p_mean  pet_mean  p_seasonality  frac_snow   aridity  \\\n",
       "gauge_id                                                           \n",
       "1013500   3.126679  1.971555       0.187940   0.313440  0.630559   \n",
       "1022500   3.608126  2.119256      -0.114530   0.245259  0.587356   \n",
       "1030500   3.274405  2.043594       0.047358   0.277018  0.624111   \n",
       "1031500   3.522957  2.071324       0.104091   0.291836  0.587950   \n",
       "1047000   3.323146  2.090024       0.147776   0.280118  0.628929   \n",
       "\n",
       "          high_prec_freq  high_prec_dur high_prec_timing  low_prec_freq  \\\n",
       "gauge_id                                                                  \n",
       "1013500            12.95       1.348958              son         202.20   \n",
       "1022500            20.55       1.205279              son         233.65   \n",
       "1030500            17.15       1.207746              son         215.60   \n",
       "1031500            18.90       1.148936              son         227.35   \n",
       "1047000            20.10       1.165217              son         235.90   \n",
       "\n",
       "          low_prec_dur  ... area_geospa_fabric frac_forest   lai_max  \\\n",
       "gauge_id                ...                                            \n",
       "1013500       3.427119  ...            2303.95      0.9063  4.167304   \n",
       "1022500       3.662226  ...             620.38      0.9232  4.871392   \n",
       "1030500       3.514262  ...            3676.09      0.8782  4.685200   \n",
       "1031500       3.473644  ...             766.53      0.9548  4.903259   \n",
       "1047000       3.691706  ...             904.94      0.9906  5.086811   \n",
       "\n",
       "          lai_diff   gvf_max  gvf_diff  dom_land_cover_frac  \\\n",
       "gauge_id                                                      \n",
       "1013500   3.340732  0.804567  0.371648             0.883452   \n",
       "1022500   3.746692  0.863936  0.337712             0.820493   \n",
       "1030500   3.665543  0.858502  0.351393             0.975258   \n",
       "1031500   3.990843  0.870668  0.398619             1.000000   \n",
       "1047000   4.300978  0.891383  0.445473             0.850450   \n",
       "\n",
       "             dom_land_cover  root_depth_50  root_depth_99  \n",
       "gauge_id                                                   \n",
       "1013500       Mixed Forests            NaN            NaN  \n",
       "1022500       Mixed Forests       0.237435       2.238444  \n",
       "1030500       Mixed Forests            NaN            NaN  \n",
       "1031500       Mixed Forests       0.250000       2.400000  \n",
       "1047000       Mixed Forests       0.241027       2.340180  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = {}\n",
    "for filename in filenames:\n",
    "    with open(os.path.join(camels_attr_dir, filename)) as f:\n",
    "        dfs[filename] = pd.read_csv(f, sep=\";\", index_col=\"gauge_id\")\n",
    "df = pd.concat([dfs[filename] for filename in filenames], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(camels_attr_dir, \"camels_attributes_concat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
